{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 살펴봅시다.\n",
    "import pandas as pd\n",
    "boston_df = pd.DataFrame(boston['data'] # 학습 데이터\n",
    "                        ,columns= boston[\"feature_names\"])\n",
    "boston_df['TARGET'] = boston['target']\n",
    "boston_df\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RM 변수와target과의 관계를 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "X_rooms = boston['data'][:, 5] # 학습 데이터의 전체 행, 5번 열\n",
    "# 산점도 그리기\n",
    "plt.scatter(X_rooms, boston['target'])\n",
    "plt.xlabel('No of rooms')\n",
    "plt.ylabel('price/1000($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산형 회귀 모델의 생성\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "\n",
    "# 학습 진행\n",
    "reg.fit(X_rooms.reshape(-1, 1)  # 학습 데이터\n",
    "        ,boston['target']) # 라벨 데이터\n",
    "#  최종 목적은 회귀 선을 위한 가중치와 절편을 구하는것\n",
    "print(\"모델의 가중치:\" ,reg.coef_)\n",
    "print(\"모델의 절편 :\" ,reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 학습 데이터와 회귀선\n",
    "import numpy as np\n",
    "pred_space = np.linspace(\n",
    "    min(X_rooms), max(X_rooms)\n",
    ").reshape(-1, 1)\n",
    "# 산점도를 그려 봅니다.\n",
    "plt.scatter(X_rooms, # x축\n",
    "            boston['target']) # y축\n",
    "\n",
    "# 회귀선\n",
    "plt.plot(pred_space,  # x축\n",
    "         reg.predict(pred_space),\n",
    "         color = \"red\"\n",
    "        ) # 우리 모델의 예측값\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston 데이터 셋 모든 특성을 이용한 예측\n",
    "# 학습 데이터, 테스트 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston['data'], boston['target'],\n",
    "    test_size=0.3, # 테스트 데이터셋 사이즈 30%\n",
    "    random_state=42 # 재현성 확보를 위한 랜덤 시드\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 학습 진행\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치와 절편\n",
    "print(\"가중치:\", reg_all.coef_)\n",
    "print(\"절편:\", reg_all.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 검증\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(reg_all.score(X_train, y_train))) # 학습 데이터\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(reg_all.score(X_test, y_test))) # 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보스턴 데이터 셋의 첫번째 데이터와 타겟\n",
    "print(\"데이터 셋 관측치:\", boston['data'][1])\n",
    "print(\"데이터 셋 label:\", boston['target'][1])\n",
    "\n",
    "# 모델이 예측한 예측치\n",
    "reg_all.predict(boston['data'][1].reshape(1, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge 회귀\n",
    "# L2 규제를 사용하여 특성의 계수(기울기)를 최소화 하는 모델\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 0.1, # 알파 계수 (규제)\n",
    "             normalize = True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Ridge 훈련 세트 점수: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Ridge 테스트 세트 점수: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso 회귀\n",
    "# L1 규제를 사용하고 특정 계수를 0으로 만들어서 영향을 없애는 효과(특성 선택)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1, # 규제 계수\n",
    "             normalize = True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "print(\"Lasso 훈련 세트 점수: {:.2f}\".format(lasso.score(X_train, y_train))) # 학습 세트\n",
    "print(\"Lasso 테스트 세트 점수: {:.2f}\".format(lasso.score(X_test, y_test))) # 테스트 세트\n",
    "print(\"계수:\", lasso.coef_)\n",
    "# 라소 회귀는 특정 계수를 0으로 만든다\n",
    "print(\"사용된 특성의 갯수:\", np.sum(lasso.coef_ !=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류용 선형 모델\n",
    "# LinearRegression, SVC(서포트 벡터 머신)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer['data'], cancer['target'],\n",
    "    stratify=cancer.target,\n",
    "    random_state = 42\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "print(\"LOGREG 훈련 세트 점수: {:.2f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"LOGREG 테스트 세트 점수: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서포트 벡터 머신 : 회귀, 분류 양쪽 모두에 사용\n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC().fit(X_train, y_train)\n",
    "print(\"SVC 훈련 세트 점수: {:.2f}\".format(svc.score(X_train, y_train)))\n",
    "print(\"SVC 훈련 테스트 점수: {:.2f}\".format(svc.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규제 강도에 따른 정확도\n",
    "# 과적합 방지\n",
    "# 선형 회귀 모델에 규제 강도별 점수\n",
    "logreg100 = LogisticRegression(C=100).fit(X_train, y_train) # 규제 C = 100\n",
    "logreg = LogisticRegression().fit(X_train, y_train) # 규제 C = 1\n",
    "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train) # 규제 C = 0.01\n",
    "\n",
    "for c, model in zip([100, 1, 0.01], [logreg100, logreg, logreg001]):\n",
    "    print(\"C={}\".format(c))\n",
    "    print(\"훈련 세트 점수: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 점수: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "# 기본적으로는 L2 규제 (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규제 방식에 따른 정확도 확인\n",
    "l1lr100 = LogisticRegression(C=100, solver='saga', penalty = \"l1\").fit(X_train, y_train)\n",
    "l1lr = LogisticRegression(solver='saga', penalty = \"l1\").fit(X_train, y_train)\n",
    "l1lr001 = LogisticRegression(C=0.01, solver='saga', penalty = \"l1\").fit(X_train, y_train)\n",
    "\n",
    "for c, model in zip([100, 1, 0.01], [l1lr100, l1lr, l1lr001]):\n",
    "    print(\"L1 규제={}\".format(c))\n",
    "    print(\"훈련 세트 점수: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 점수: {:.2f}\".format(model.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
